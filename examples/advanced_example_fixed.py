#!/usr/bin/env python3
"""
é«˜çº§åŠŸèƒ½ç¤ºä¾‹ - å±•ç¤ºæ‰€æœ‰é«˜çº§ç‰¹æ€§ï¼ˆä¿®å¤ç‰ˆæœ¬ï¼‰
"""

import os
import sys
import numpy as np
import torch
import torch.nn as nn
import torch.optim as optim
from pathlib import Path
import time

# æ·»åŠ çˆ¶ç›®å½•åˆ°è·¯å¾„
sys.path.insert(0, str(Path(__file__).parent.parent))

import wandb_local as wandb


class AdvancedModel(nn.Module):
    """å¸¦æœ‰å¤šä¸ªå±‚çš„å¤æ‚æ¨¡å‹"""
    
    def __init__(self, input_size, hidden_sizes, output_size, dropout_rate=0.5):
        super().__init__()
        self.layers = nn.ModuleList()
        
        # è¾“å…¥å±‚
        self.layers.append(nn.Linear(input_size, hidden_sizes[0]))
        self.layers.append(nn.ReLU())
        self.layers.append(nn.Dropout(dropout_rate))
        
        # éšè—å±‚
        for i in range(len(hidden_sizes) - 1):
            self.layers.append(nn.Linear(hidden_sizes[i], hidden_sizes[i+1]))
            self.layers.append(nn.ReLU())
            self.layers.append(nn.Dropout(dropout_rate))
        
        # è¾“å‡ºå±‚
        self.layers.append(nn.Linear(hidden_sizes[-1], output_size))
        
    def forward(self, x):
        for layer in self.layers:
            x = layer(x)
        return x


def create_sample_images(n_images=5):
    """åˆ›å»ºç¤ºä¾‹å›¾åƒæ•°æ®"""
    images = []
    for i in range(n_images):
        # åˆ›å»ºä¸åŒæ¨¡å¼çš„å›¾åƒ
        if i % 3 == 0:
            # éšæœºå™ªå£°
            img = np.random.rand(64, 64, 3) * 255
        elif i % 3 == 1:
            # æ¸å˜å›¾åƒ
            x = np.linspace(0, 255, 64)
            y = np.linspace(0, 255, 64)
            xx, yy = np.meshgrid(x, y)
            img = np.stack([xx, yy, xx+yy], axis=-1) % 255
        else:
            # åœ†å½¢å›¾æ¡ˆ
            center = (32, 32)
            radius = 20
            img = np.zeros((64, 64, 3))
            for y in range(64):
                for x in range(64):
                    dist = np.sqrt((x - center[0])**2 + (y - center[1])**2)
                    if dist <= radius:
                        img[y, x] = [255, 100, 100]
        
        images.append(img.astype(np.uint8))
    return images


def create_sample_audio(duration=2, sample_rate=44100):
    """åˆ›å»ºç¤ºä¾‹éŸ³é¢‘æ•°æ®"""
    t = np.linspace(0, duration, int(sample_rate * duration))
    
    # åˆ›å»ºå¤åˆéŸ³è°ƒ
    freq1 = 440  # A4
    freq2 = 554  # C#5
    freq3 = 659  # E5
    
    audio = (np.sin(2 * np.pi * freq1 * t) * 0.3 + 
             np.sin(2 * np.pi * freq2 * t) * 0.2 + 
             np.sin(2 * np.pi * freq3 * t) * 0.1)
    
    # æ·»åŠ è¡°å‡
    audio *= np.exp(-t * 2)
    
    return audio.astype(np.float32)


def create_sample_video(n_frames=16, height=64, width=64):
    """åˆ›å»ºç¤ºä¾‹è§†é¢‘æ•°æ®"""
    video = []
    
    for frame_idx in range(n_frames):
        frame = np.zeros((height, width, 3), dtype=np.uint8)
        
        # ç§»åŠ¨çš„åœ†å½¢
        center_x = int(width // 2 + 20 * np.sin(frame_idx * 2 * np.pi / n_frames))
        center_y = height // 2
        radius = 10
        
        for y in range(height):
            for x in range(width):
                dist = np.sqrt((x - center_x)**2 + (y - center_y)**2)
                if dist <= radius:
                    frame[y, x] = [255, 255, 100]
        
        video.append(frame)
    
    return np.array(video)


def main():
    """ä¸»å‡½æ•°"""
    print("ğŸš€ WandB Local é«˜çº§åŠŸèƒ½ç¤ºä¾‹ï¼ˆä¿®å¤ç‰ˆæœ¬ï¼‰")
    print("=" * 60)
    
    # å®éªŒé…ç½®
    config = {
        "learning_rate": 0.001,
        "epochs": 3,  # å‡å°‘epochæ•°ä»¥åŠ å¿«æµ‹è¯•
        "batch_size": 64,
        "input_size": 100,
        "hidden_sizes": [128, 64, 32],
        "output_size": 10,
        "dropout_rate": 0.3,
        "n_samples": 500,  # å‡å°‘æ ·æœ¬æ•°ä»¥åŠ å¿«æµ‹è¯•
        "experiment_type": "advanced_features_demo"
    }
    
    # åˆå§‹åŒ–å®éªŒ
    print("ğŸ“Š åˆå§‹åŒ–é«˜çº§å®éªŒ...")
    run = wandb.init(
        project="advanced-example-fixed",
        name="feature-demonstration-fixed",
        config=config,
        tags=["demo", "advanced", "multimedia", "artifacts"],
        notes="å±•ç¤ºæ‰€æœ‰é«˜çº§åŠŸèƒ½çš„ç»¼åˆç¤ºä¾‹ï¼ˆä¿®å¤ç‰ˆæœ¬ï¼‰"
    )
    
    print(f"âœ… å®éªŒå·²å¯åŠ¨: {run.run_id}")
    print(f"ğŸ“ æ•°æ®å­˜å‚¨è·¯å¾„: {run.dir}")
    
    # åˆ›å»ºæ¨¡å‹
    print("ğŸ§  åˆ›å»ºå¤æ‚æ¨¡å‹...")
    model = AdvancedModel(
        config["input_size"],
        config["hidden_sizes"],
        config["output_size"],
        config["dropout_rate"]
    )
    
    # ç›‘æ§æ¨¡å‹
    print("ğŸ‘€ ç›‘æ§æ¨¡å‹ï¼ˆæ¢¯åº¦+å‚æ•°ï¼‰...")
    wandb.watch(model, log="all", log_freq=25)
    
    # è®¾ç½®è®­ç»ƒ
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=config["learning_rate"])
    
    # ç”Ÿæˆæ•°æ®
    print("ğŸ“Š ç”Ÿæˆè®­ç»ƒæ•°æ®...")
    X_train = torch.randn(config["n_samples"], config["input_size"])
    y_train = torch.randint(0, config["output_size"], (config["n_samples"],))
    
    X_val = torch.randn(config["n_samples"] // 4, config["input_size"])
    y_val = torch.randint(0, config["output_size"], (config["n_samples"] // 4,))
    
    # åˆ›å»ºç»“æœè¡¨æ ¼
    results_table = wandb.Table(columns=[
        "epoch", "batch_idx", "train_loss", "val_loss", 
        "accuracy", "learning_rate", "grad_norm"
    ])
    
    # è®­ç»ƒå¾ªç¯
    print("ğŸƒ å¼€å§‹è®­ç»ƒ...")
    for epoch in range(config["epochs"]):
        model.train()
        total_loss = 0
        n_batches = len(X_train) // config["batch_size"]
        
        for batch_idx in range(n_batches):
            # è·å–æ‰¹æ¬¡æ•°æ®
            start_idx = batch_idx * config["batch_size"]
            end_idx = start_idx + config["batch_size"]
            
            batch_X = X_train[start_idx:end_idx]
            batch_y = y_train[start_idx:end_idx]
            
            # å‰å‘ä¼ æ’­
            optimizer.zero_grad()
            outputs = model(batch_X)
            loss = criterion(outputs, batch_y)
            
            # åå‘ä¼ æ’­
            loss.backward()
            
            # è®¡ç®—æ¢¯åº¦èŒƒæ•°
            grad_norm = 0
            for param in model.parameters():
                if param.grad is not None:
                    grad_norm += param.grad.data.norm(2).item() ** 2
            grad_norm = grad_norm ** 0.5
            
            optimizer.step()
            total_loss += loss.item()
            
            # è®°å½•æ‰¹æ¬¡æŒ‡æ ‡
            if batch_idx % 10 == 0:
                wandb.log({
                    "batch_loss": loss.item(),
                    "batch_grad_norm": grad_norm,
                    "batch_idx": batch_idx,
                    "epoch": epoch
                })
        
        # éªŒè¯
        model.eval()
        with torch.no_grad():
            val_outputs = model(X_val)
            val_loss = criterion(val_outputs, y_val)
            
            _, predicted = torch.max(val_outputs, 1)
            accuracy = (predicted == y_val).float().mean().item()
        
        avg_train_loss = total_loss / n_batches
        
        # è®°å½•epochæŒ‡æ ‡
        print(f"Epoch {epoch+1}/{config['epochs']} - "
              f"Loss: {avg_train_loss:.4f} - "
              f"Val Loss: {val_loss.item():.4f} - "
              f"Accuracy: {accuracy:.4f} - "
              f"Grad Norm: {grad_norm:.4f}")
        
        wandb.log({
            "epoch": epoch,
            "train_loss": avg_train_loss,
            "val_loss": val_loss.item(),
            "accuracy": accuracy,
            "grad_norm": grad_norm,
            "learning_rate": optimizer.param_groups[0]["lr"]
        })
        
        # æ·»åŠ åˆ°ç»“æœè¡¨æ ¼
        results_table.add_data(
            epoch, batch_idx, avg_train_loss, val_loss.item(),
            accuracy, optimizer.param_groups[0]["lr"], grad_norm
        )
        
        # æ¯2ä¸ªepochè®°å½•å¤šåª’ä½“æ•°æ®
        if epoch % 2 == 0:
            print(f"ğŸ¨ è®°å½•å¤šåª’ä½“æ•°æ® (epoch {epoch})...")
            
            # è®°å½•å›¾åƒ
            images = create_sample_images(3)
            image_captions = [f"Epoch {epoch} - Image {i}" for i in range(len(images))]
            wandb.log({
                "sample_images": [wandb.Image(img, caption=caption) 
                                for img, caption in zip(images, image_captions)]
            })
            
            # è®°å½•éŸ³é¢‘
            audio = create_sample_audio(duration=1)
            wandb.log({
                "sample_audio": wandb.Audio(audio, 44100, 
                                          caption=f"è®­ç»ƒéŸ³é¢‘ - Epoch {epoch}")
            })
            
            # è®°å½•è§†é¢‘
            video = create_sample_video(n_frames=8)
            wandb.log({
                "sample_video": wandb.Video(video, fps=2, 
                                          caption=f"è®­ç»ƒè§†é¢‘ - Epoch {epoch}")
            })
    
    # è®°å½•æœ€ç»ˆè¡¨æ ¼
    print("ğŸ“‹ è®°å½•ç»“æœè¡¨æ ¼...")
    wandb.log({"training_results": results_table})
    
    # åˆ›å»ºå’Œä¿å­˜æ¨¡å‹Artifact
    print("ğŸ“¦ åˆ›å»ºæ¨¡å‹Artifact...")
    model_artifact = wandb.Artifact(
        "trained-model", 
        type="model",
        description=f"åœ¨{config['epochs']}ä¸ªepochåè®­ç»ƒçš„æ¨¡å‹",
        metadata={
            "final_accuracy": accuracy,
            "total_epochs": config["epochs"],
            "model_architecture": "AdvancedModel",
            "hidden_sizes": config["hidden_sizes"]
        }
    )
    
    # ä¿å­˜æ¨¡å‹
    model_path = "final_model.pth"
    torch.save({
        'model_state_dict': model.state_dict(),
        'config': config,
        'final_accuracy': accuracy,
        'epochs_trained': config["epochs"]
    }, model_path)
    
    model_artifact.add_file(model_path)
    wandb.log({"final_model": model_artifact})
    
    # åˆ›å»ºæ•°æ®Artifact
    print("ğŸ“Š åˆ›å»ºæ•°æ®Artifact...")
    data_artifact = wandb.Artifact(
        "training-data",
        type="dataset",
        description="ç”¨äºè®­ç»ƒçš„è™šæ‹Ÿæ•°æ®é›†"
    )
    
    # ä¿å­˜è®­ç»ƒæ•°æ®ï¼ˆç¤ºä¾‹ï¼‰
    train_data_path = "train_data_sample.npy"
    np.save(train_data_path, X_train[:100].numpy())  # åªä¿å­˜ä¸€å°éƒ¨åˆ†ä½œä¸ºç¤ºä¾‹
    data_artifact.add_file(train_data_path)
    
    wandb.log({"training_data": data_artifact})
    
    # åˆ›å»ºé…ç½®Artifact
    print("âš™ï¸ åˆ›å»ºé…ç½®Artifact...")
    config_artifact = wandb.Artifact(
        "experiment-config",
        type="config",
        description="å®éªŒé…ç½®æ–‡ä»¶"
    )
    
    import json
    config_path = "experiment_config.json"
    with open(config_path, 'w') as f:
        json.dump(config, f, indent=2)
    
    config_artifact.add_file(config_path)
    wandb.log({"experiment_config": config_artifact})
    
    # å‘é€å‘Šè­¦
    print("ğŸ”” å‘é€å®Œæˆå‘Šè­¦...")
    wandb.alert(
        title="é«˜çº§å®éªŒå®Œæˆ",
        text=f"æ‰€æœ‰é«˜çº§åŠŸèƒ½æ¼”ç¤ºå®Œæˆï¼\n"
              f"æœ€ç»ˆå‡†ç¡®ç‡: {accuracy:.3f}\n"
              f"æ€»è®­ç»ƒè½®æ•°: {config['epochs']}\n"
              f"æ¨¡å‹å·²ä¿å­˜åˆ°Artifact",
        level="SUCCESS",
        wait_duration=5
    )
    
    # ç»“æŸå®éªŒ
    print("ğŸ ç»“æŸå®éªŒ...")
    wandb.finish()
    
    print("\nâœ… é«˜çº§å®éªŒå®Œæˆï¼")
    print(f"ğŸ“Š æŸ¥çœ‹ç»“æœ: {run.dir}")
    print(f"ğŸ”— è¿è¡ŒID: {run.run_id}")
    
    # æ˜¾ç¤ºå®éªŒæ‘˜è¦ï¼ˆç›´æ¥ä»runå¯¹è±¡è·å–ï¼‰
    print(f"\nğŸ“ˆ å®éªŒæ‘˜è¦:")
    for key, value in run.summary.items():
        if isinstance(value, (int, float)):
            print(f"   {key}: {value:.4f}")
        else:
            print(f"   {key}: {value}")
    
    # æ˜¾ç¤ºä¿å­˜çš„æ–‡ä»¶
    print(f"\nğŸ’¾ ä¿å­˜çš„æ–‡ä»¶:")
    if os.path.exists(run.dir):
        for root, dirs, files in os.walk(run.dir):
            level = root.replace(run.dir, '').count(os.sep)
            indent = ' ' * 2 * level
            print(f"{indent}{os.path.basename(root)}/")
            subindent = ' ' * 2 * (level + 1)
            for file in files[:10]:  # åªæ˜¾ç¤ºå‰10ä¸ªæ–‡ä»¶
                print(f"{subindent}{file}")
            if len(files) > 10:
                print(f"{subindent}... è¿˜æœ‰ {len(files) - 10} ä¸ªæ–‡ä»¶")


if __name__ == "__main__":
    main()